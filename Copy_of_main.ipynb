{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rberbenkova/project-1-deep-learning-image-classification-with-cnn/blob/main/Copy_of_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project I | Deep Learning: Image Classification with CNN**"
      ],
      "metadata": {
        "id": "iFn1sSsGh1BV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4rCKcndPybL"
      },
      "source": [
        "# **Task Description:**\n",
        "Students will build a Convolutional Neural Network (CNN) model to classify images from a given dataset into predefined categories/classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**## Datasets (pick one!)**\n",
        "\n",
        "The dataset for this task is the **CIFAR-10** dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. You can download the dataset from here.\n",
        "(https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "The **second dataset** contains about 28,000 medium quality animal images belonging to 10 categories: dog, cat, horse, spyder, butterfly, chicken, sheep, cow, squirrel, elephant. The link is here.\n",
        "(https://www.kaggle.com/datasets/alessiocorrado99/animals10/data)"
      ],
      "metadata": {
        "id": "bS3Yh35JiXQt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wkicuxZdrdq"
      },
      "source": [
        "# Assessment Components\n",
        "\n",
        "**Data Preprocessing**\n",
        "*   Data loading and preprocessing (e.g., normalization, resizing,\n",
        "augmentation).\n",
        "*   Create visualizations of some images, and labels.\n",
        "\n",
        "\n",
        "**Model Architecture**\n",
        "* Design a CNN architecture suitable for image classification\n",
        "* Include convolutional layers, pooling layers, and fully connected layers.\n",
        "\n",
        "\n",
        "**Model Training**\n",
        "*   Train the CNN model using appropriate optimization techniques (e.g., stochastic gradient descent, Adam).\n",
        "*   Utilize techniques such as early stopping to prevent overfitting.\n",
        "\n",
        "\n",
        "**Model Evaluation**\n",
        "\n",
        "Evaluate the trained model on a separate validation set.\n",
        "Compute and report metrics such as accuracy, precision, recall, and F1-score.\n",
        "Visualize the confusion matrix to understand model performance across different classes.\n",
        "Transfer Learning\n",
        "\n",
        "Evaluate the accuracy of your model on a pre-trained models like ImagNet, VGG16, Inception... (pick one an justify your choice)\n",
        "You may find this link helpful.\n",
        "This is the Pytorch version.\n",
        "Perform transfer learning with your chosen pre-trained models i.e., you will probably try a few and choose the best one.\n",
        "Code Quality\n",
        "\n",
        "Well-structured and commented code.\n",
        "Proper documentation of functions and processes.\n",
        "Efficient use of libraries and resources.\n",
        "Report\n",
        "\n",
        "Write a concise report detailing the approach taken, including:\n",
        "Description of the chosen CNN architecture.\n",
        "Explanation of preprocessing steps.\n",
        "Details of the training process (e.g., learning rate, batch size, number of epochs).\n",
        "Results and analysis of models performance.\n",
        "What is your best model. Why?\n",
        "Insights gained from the experimentation process.\n",
        "Include visualizations and diagrams where necessary.\n",
        "Model deployment\n",
        "\n",
        "Pick the best model\n",
        "Build an app using Flask - Can you host somewhere other than your laptop? +5 Bonus points if you use Tensorflow Serving\n",
        "User should be able to upload one or multiples images get predictions including probabilities for each prediction\n",
        "Evaluation Criteria\n",
        "Accuracy of the trained models on the validation set. 30 points\n",
        "Clarity and completeness of the report. 20 points\n",
        "Quality of code implementation. 5 points\n",
        "Proper handling of data preprocessing and models training. 30 points\n",
        "Demonstration of understanding key concepts of deep learning. 5 points\n",
        "Model deployment. 10 points\n",
        "Passing Score is 70 points.\n",
        "\n",
        "Submission Details\n",
        "Deadline for submission: end of the week or as communicated by your teaching team.\n",
        "Submit the following:\n",
        "Python code files (*.py, ipynb) containing the model implementation and training process.\n",
        "A data folder with 5-10 images to test the deployed model/app if hosted somewhere else other than your laptop (strongly recommended! Not a must have)\n",
        "A PDF report documenting the approach, results, and analysis.\n",
        "Any additional files necessary for reproducing the results (e.g., requirements.txt, README.md).\n",
        "PPT presentation\n",
        "Additional Notes\n",
        "Students are encourage to experiment with different architectures, hyper-parameters, and optimization techniques.\n",
        "Provide guidance and resources for troubleshooting common issues during model training and evaluation.\n",
        "Students will discuss their approaches and findings in class during assessment evaluation sessions.\n",
        "\n",
        "*   Visualize the images in CIFAR-10 dataset. Create a 10 x 10 plot showing 10 random samples from each class.\n",
        "*   Convert the labels to one-hot encoded form.\n",
        "*   Normalize the images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrb20KGMtTFq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnlMfaqJgsRj"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ER5WlMNRydp"
      },
      "source": [
        "## Define the following model (same as the one in tutorial)\n",
        "\n",
        "For the convolutional front-end, start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer.\n",
        "\n",
        "Use the input as (32,32,3).\n",
        "\n",
        "The filter maps can then be flattened to provide features to the classifier.\n",
        "\n",
        "Use a dense layer with 100 units before the classification layer (which is also a dense layer with softmax activation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfWCHxh8HGhN",
        "outputId": "b036db94-2ab2-43bd-b1e3-1892889cc232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\drago\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSN6riPISBMG"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGtivbQJT39U"
      },
      "source": [
        "*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n",
        "*   Use the above defined model to train CIFAR-10 and train the model for 50 epochs with a batch size of 512."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn8UzPBZugVp"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpTMVXEGgsRm"
      },
      "source": [
        "*   Plot the cross entropy loss curve and the accuracy curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqVHSQXagsRm"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2mrWK5hSB_o"
      },
      "source": [
        "## Defining Deeper Architectures: VGG Models\n",
        "\n",
        "*   Define a deeper model architecture for CIFAR-10 dataset and train the new model for 50 epochs with a batch size of 512. We will use VGG model as the architecture.\n",
        "\n",
        "Stack two convolutional layers with 32 filters, each of 3 x 3.\n",
        "\n",
        "Use a max pooling layer and next flatten the output of the previous layer and add a dense layer with 128 units before the classification layer.\n",
        "\n",
        "For all the layers, use ReLU activation function.\n",
        "\n",
        "Use same padding for the layers to ensure that the height and width of each layer output matches the input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A80vLxW9FIek"
      },
      "outputs": [],
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgca5dUNSFNc"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwaPphEBUtlC"
      },
      "source": [
        "*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n",
        "*   Use the above defined model to train CIFAR-10 and train the model for 50 epochs with a batch size of 512."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc2qtU0mUvVA"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2cRr2ZFSFds"
      },
      "source": [
        "*   Compare the performance of both the models by plotting the loss and accuracy curves of both the training steps. Does the deeper model perform better? Comment on the observation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8OSHAf5SJPr"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9kU3wa3Rei"
      },
      "source": [
        "**Comment on the observation**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzXmO1WoSKMY"
      },
      "source": [
        "*   Use predict function to predict the output for the test split\n",
        "*   Plot the confusion matrix for the new model and comment on the class confusions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DObaoxhaSMUg"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUBrvRomU5O_"
      },
      "source": [
        "**Comment here :**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffwVz-FLSNG7"
      },
      "source": [
        "*    Print the test accuracy for the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4WX3_uLSN5I"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dySqfA6PVBjQ"
      },
      "source": [
        "## Define the complete VGG architecture.\n",
        "\n",
        "Stack two convolutional layers with 64 filters, each of 3 x 3 followed by max pooling layer.\n",
        "\n",
        "Stack two more convolutional layers with 128 filters, each of 3 x 3, followed by max pooling, followed by two more convolutional layers with 256 filters, each of 3 x 3, followed by max pooling.\n",
        "\n",
        "Flatten the output of the previous layer and add a dense layer with 128 units before the classification layer.\n",
        "\n",
        "For all the layers, use ReLU activation function.\n",
        "\n",
        "Use same padding for the layers to ensure that the height and width of each layer output matches the input\n",
        "\n",
        "*   Change the size of input to 64 x 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm35siILFNT0"
      },
      "outputs": [],
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH4lDVBuVA_Q"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu_B8kJGWhcM"
      },
      "source": [
        "*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n",
        "*   Use the above defined model to train CIFAR-10 and train the model for 10 epochs with a batch size of 512.\n",
        "*   Predict the output for the test split and plot the confusion matrix for the new model and comment on the class confusions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4elnDWnjEbmO"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dlzFt0SXGDQ"
      },
      "source": [
        "# Understanding deep networks\n",
        "\n",
        "*   What is the use of activation functions in network? Why is it needed?\n",
        "*   We have used softmax activation function in the exercise. There are other activation functions available too. What is the difference between sigmoid activation and softmax activation?\n",
        "*   What is the difference between categorical crossentropy and binary crossentropy loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPy_1EWXX6fp"
      },
      "source": [
        "**Write the answers below :**\n",
        "\n",
        "1 - Use of activation functions:\n",
        "\n",
        "\n",
        "\n",
        "_\n",
        "\n",
        "2 - Key Differences between sigmoid and softmax:\n",
        "\n",
        "\n",
        "\n",
        "_\n",
        "\n",
        "3 - Key Differences between categorical crossentropy and binary crossentropy loss:\n",
        "\n",
        "\n",
        "_\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}